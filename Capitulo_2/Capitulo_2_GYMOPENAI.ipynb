{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 2: Introducción a GYM de OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este capítulo se aprende a implementar la teoría aprendida en el capítulo anterior, se diseña un ambiente muy simple de apredizaje con refuerzo así como su agente correspondiente. En la segunda parte de este notebook se realiza un ejemplo pequeño con el juego de CartPole el cual se le mete cierta aleatoriedad con los Wrappers y se guardan los progresos en videos usando los Monitores. Así mismo se define la forma de incializar un ambiente pre definido en GYM usnado la función enviroment.make('name') y agregando los monitores como enviroment.wrappers.Monitor(enviroment,directorio,force(reescribir los datos existentes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Ambiente:\n",
    "    def __init__(self):\n",
    "        self.steps_left=100 # Los pasos que faltan para que se aprenda\n",
    "    def get_observation(self):\n",
    "        return [0.0,0.0,0.0]\n",
    "    def get_action(self):\n",
    "        return [0,1]\n",
    "    def is_done(self):\n",
    "        return self.steps_left==0\n",
    "    def action(self,action):\n",
    "        if self.is_done():\n",
    "            raise Exception(\"Game is over\")\n",
    "        self.steps_left-=1\n",
    "        return random.random()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agente:\n",
    "    def __init__(self):\n",
    "        self.cummulative_reward=0.0\n",
    "    def step(self,env): #Este paso es el que da la interacción del agente con su ambiente\n",
    "        current_obs=env.get_observation()\n",
    "        actions=env.get_action()\n",
    "        reward=env.action(random.choice(actions))\n",
    "        self.cummulative_reward+=reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=Agente()\n",
    "enviroment=Ambiente()\n",
    "while not enviroment.is_done():\n",
    "    agent.step(enviroment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancia acumulada es 55.654411394295494\n"
     ]
    }
   ],
   "source": [
    "print(\"Ganancia acumulada es {}\".format(agent.cummulative_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parte 2 creación del entrenamiento de cart-pole usnado los Wrapers, esto permite meter cierta aleatoriedad a \n",
    "#las cosas para que el agente haga acciones un poco más diferentes\n",
    "import gym\n",
    "from typing import TypeVar\n",
    "Action=TypeVar('Action')\n",
    "class RandomActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self,env,epsilon=0.3): #La probabilidad de tomar una acción aleatoria un poco diferente a las demás\n",
    "        super(RandomActionWrapper,self).__init__(env)\n",
    "        self.epsilon=epsilon #Inicializamos la clase padre de este wrapper como lo es el ambiente\n",
    "    def action(self,action:Action)->Action:\n",
    "        if random.random()<self.epsilon:\n",
    "            print(\"Aleatorio!!\")\n",
    "            return self.env.action_space.sample()\n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=RandomActionWrapper(gym.make(\"CartPole-v0\"))\n",
    "env=gym.wrappers.Monitor(env,\"runs\",force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleatorio!!\n",
      "Aleatorio!!\n",
      "Aleatorio!!\n",
      "Aleatorio!!\n",
      "Aleatorio!!\n",
      "Aleatorio!!\n",
      "Recompensa total: 13.0\n"
     ]
    }
   ],
   "source": [
    "#Parte del entrenamiento de Cart Pole\n",
    "expected_goal=12\n",
    "total_reward=0.0\n",
    "while total_reward<expected_goal:\n",
    "    obs=env.reset() #Regresamos al estado inicial\n",
    "    total_reward=0.0\n",
    "    while True:\n",
    "        obs,reward,done,_=env.step(1) \n",
    "        total_reward+=reward\n",
    "        if done:\n",
    "            break\n",
    "print(\"Recompensa total: {}\".format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
